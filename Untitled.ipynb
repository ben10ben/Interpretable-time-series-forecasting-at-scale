{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b496d73-f197-4f04-b2e0-2bf06518179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tensorboard as tb\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from torch import nn\n",
    "from pytorch_lightning.accelerators import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, DeviceStatsMonitor\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from dataloading_helpers import retail_dataloader, retail_formatter\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac9adb-4358-4610-ae29-24a67cb5b740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\favorita-grocery-sales-forecasting.zip\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\holidays_events.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\items.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\oil.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\sample_submission.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\stores.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\test.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\train.csv.7z\n",
      "Unzipping file: C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\\transactions.csv.7z\n",
      "Unzipping complete, commencing data processing...\n",
      "Regenerating data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\dataloading_helpers\\retail_dataloader.py:91: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  start_date = pd.datetime(2015, 1, 1)\n",
      "C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\dataloading_helpers\\retail_dataloader.py:92: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  end_date = pd.datetime(2016, 6, 1)\n",
      "C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\dataloading_helpers\\retail_dataloader.py:97: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temporal = pd.read_csv(os.path.join(data_folder, 'train.csv'), index_col=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing returns data\n",
      "Resampling to regular grid\n",
      "Adding oil\n",
      "Adding store info\n",
      "Adding item info\n",
      "Adding holidays\n",
      "Saving processed file to C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\data\\retail\n"
     ]
    }
   ],
   "source": [
    "train, test, validation = retail_dataloader.create_retail_timeseries_tft()\n",
    "timeseries_dict =  retail\n",
    "config_name_string = \"retail\"\n",
    "parameters = []\n",
    "model_dir = CONFIG_DICT[\"models\"][config_name_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19332a46-5820-44c5-8082-c2b1d67eebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77047f60-5bcd-408d-b443-0819f992470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>traj_id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>open</th>\n",
       "      <th>date</th>\n",
       "      <th>log_sales</th>\n",
       "      <th>oil</th>\n",
       "      <th>...</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>national_hol</th>\n",
       "      <th>regional_hol</th>\n",
       "      <th>local_hol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10_1001305</td>\n",
       "      <td>10_1001305_2015-01-02 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>-0.413818</td>\n",
       "      <td>0.504883</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.738281</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10_1001305</td>\n",
       "      <td>10_1001305_2015-01-04 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>-0.790039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.770508</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10_1001305</td>\n",
       "      <td>10_1001305_2015-01-05 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>-0.790039</td>\n",
       "      <td>0.072571</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.761230</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10_1001305</td>\n",
       "      <td>10_1001305_2015-01-06 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>-0.790039</td>\n",
       "      <td>-0.262695</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.716309</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10_1001305</td>\n",
       "      <td>10_1001305_2015-01-07 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>-0.413818</td>\n",
       "      <td>-0.147705</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.833496</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr  item_nbr  unit_sales  onpromotion     traj_id  \\\n",
       "0          1         1         3.0            0  10_1001305   \n",
       "2          1         1         2.0            0  10_1001305   \n",
       "3          1         1         2.0            0  10_1001305   \n",
       "4          1         1         2.0            0  10_1001305   \n",
       "5          1         1         3.0            0  10_1001305   \n",
       "\n",
       "                        unique_id  open       date  log_sales       oil  ...  \\\n",
       "0  10_1001305_2015-01-02 00:00:00     1 2015-01-02  -0.413818  0.504883  ...   \n",
       "2  10_1001305_2015-01-04 00:00:00     1 2015-01-04  -0.790039       NaN  ...   \n",
       "3  10_1001305_2015-01-05 00:00:00     1 2015-01-05  -0.790039  0.072571  ...   \n",
       "4  10_1001305_2015-01-06 00:00:00     1 2015-01-06  -0.790039 -0.262695  ...   \n",
       "5  10_1001305_2015-01-07 00:00:00     1 2015-01-07  -0.413818 -0.147705  ...   \n",
       "\n",
       "   family  class  perishable  transactions  day_of_week  day_of_month  month  \\\n",
       "0      10      9           0     -0.738281            4             2      1   \n",
       "2      10      9           0     -0.770508            6             4      1   \n",
       "3      10      9           0     -0.761230            0             5      1   \n",
       "4      10      9           0     -0.716309            1             6      1   \n",
       "5      10      9           0     -0.833496            2             7      1   \n",
       "\n",
       "   national_hol  regional_hol  local_hol  \n",
       "0            19             4         24  \n",
       "2            54             4         24  \n",
       "3            54             4         24  \n",
       "4            54             4         24  \n",
       "5            54             4         24  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4382f-1fde-48e0-a76d-ac34a4108470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing modules...\n",
      "Preparing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-04 14:31:09,151]\u001b[0m A new study created in memory with name: no-name-2de26a1c-68a9-49a7-8d22-474de4bdc72e\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6734ba03be43eb80359956c99b3c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Restoring states from the checkpoint path at C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\.lr_find_8adb9c78-ec14-4253-ad54-6616c2e6a44f.ckpt\n",
      "Restored all states from the checkpoint file at C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\.lr_find_8adb9c78-ec14-4253-ad54-6616c2e6a44f.ckpt\n",
      "\u001b[32m[I 2023-03-04 14:33:21,639]\u001b[0m Using learning rate of 0.00198\u001b[0m\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\optuna\\integration\\pytorch_lightning.py:52: UserWarning: The metric 'val_loss' is not in the evaluation logs for pruning. Please make sure you set the correct metric name.\n",
      "  warnings.warn(message)\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "\u001b[32m[I 2023-03-04 15:05:54,553]\u001b[0m Trial 0 finished with value: 0.28909581899642944 and parameters: {'gradient_clip_val': 0.3212525138750618, 'hidden_size': 16, 'dropout': 0.10785436359834565, 'hidden_continuous_size': 15, 'attention_head_size': 2, 'learning_rate': 0.0019826123320599316}. Best is trial 0 with value: 0.28909581899642944.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:262: UserWarning: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:94: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3d81cdd89c47ed9b2ae380ec4ee4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Restoring states from the checkpoint path at C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\.lr_find_4a6b8276-4874-47b0-a010-a13b22d7c48e.ckpt\n",
      "Restored all states from the checkpoint file at C:\\Users\\Benedikt\\Desktop\\Mein_Ordner\\WI-INFO\\Semester_4\\Information_Systems\\TFT_project\\RT1_TFT\\.lr_find_4a6b8276-4874-47b0-a010-a13b22d7c48e.ckpt\n",
      "\u001b[32m[I 2023-03-04 15:16:48,595]\u001b[0m Using learning rate of 0.000896\u001b[0m\n",
      "C:\\Users\\Benedikt\\anaconda_main\\lib\\site-packages\\optuna\\integration\\pytorch_lightning.py:52: UserWarning: The metric 'val_loss' is not in the evaluation logs for pruning. Please make sure you set the correct metric name.\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing modules...\")\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import tensorboard as tb\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from torch import nn\n",
    "from pytorch_lightning.accelerators import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, DeviceStatsMonitor\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from dataloading_helpers import electricity_dataloader\n",
    "from config import *\n",
    "import pickle\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "print(\"Preparing dataset...\") \n",
    "  \n",
    "electricity = electricity_dataloader.create_electricity_timeseries_tft()\n",
    "timeseries_dict =  electricity\n",
    "config_name_string = \"electricity\"\n",
    "parameters = []\n",
    "model_dir = CONFIG_DICT[\"models\"][config_name_string]\n",
    "\n",
    "\n",
    "\n",
    "  # create study\n",
    "study = optimize_hyperparameters(\n",
    "    electricity[\"train_dataloader\"],\n",
    "    electricity[\"val_dataloader\"],\n",
    "    model_path=\"hyperparameters_electricity\",\n",
    "    n_trials=100,\n",
    "    max_epochs=20,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(16, 256),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.0005, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=40, max_epochs=20, log_every_n_steps=5),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=True,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "    optimizer=\"adam\"\n",
    "  )\n",
    "\n",
    "  # save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
